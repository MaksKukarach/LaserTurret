# Библиотеки для работы с видео, последовательным портом и системными ресурсами
import cv2, serial, psutil
# Модуль для обнаружения позы человека
from cvzone.PoseModule import PoseDetector
# Модуль для выведения информации о хипе (куче)
from guppy import hpy
# Модуль с дополнительными функциями для робота
import features

# Получаем сводку об использовании памяти системы
print(psutil.virtual_memory())

# Создаем объект для работы с последовательным портом со скоростью 9600
ser = serial.Serial("COM4", 9600)

# Создаем объект для обнаружения позы человека
detector = PoseDetector()

# Создаем объект для захвата видео с камеры (значение 0 выбирает камеру по умолчанию)
videocapture = cv2.VideoCapture(0)

# Получаем и выводим информацию о типе, количестве и размере объектов в хипе (куче)
h = hpy()
print(h.heap())

# Забавная фича - робот начинает хаотично двигаться, имитируя танец
DANCE = True
if DANCE == True:
    features.dance(ser)

# Инициализируем значения последних координат X и Y
last_x = 0
last_y = 0

while True:
    # Читаем кадр из видеопотока
    success, frame = videocapture.read()

    # Если не удалось прочитать кадр, выходим из цикла
    if not success:
        print("Не удалось получить изображение. Выключаюсь...")
        break

    # Обнаруживаем позу человека на кадре и сохраняем метки в переменную frame
    frame = detector.findPose(frame)

    # Считываем координаты человека на кадре по меткам в переменную pose_data
    _, pose_data = detector.findPosition(frame) 

    # Если координаты не пустые
    if pose_data != dict():

        # Считываем координаты X и Y с переменной pose_data
        X = 120 - int(pose_data.get('center', 0)[0] / 6) # Отнимая значение от 180, мы инвертируем направление (особенность сервопривода)
        Y = int( (pose_data.get('center', 0)[1]) / 6)

        # Если с предыдущего кадра координаты изменились хотя бы на заданный минимум
        if abs(X - last_x) >= 2 or abs(Y - last_y) > 1:

            # Отправляем координаты в порт роботу
            ser.write(str.encode(f"X{X}Y{Y}"))

            # Обновляем значение последних координат на текущие (для использования в следующей итерации)
            last_x = X
            last_y = Y

            # Выводим данные в консоль
            print(X, Y)
            # print(pose_data)
        
    # Выводим модифицированный кадр на экран
    cv2.imshow("human detection", frame)
    
    # Цикл экстренно завершится, если будет нажата кнопка 'q' (с латинской раскладкой)
    if cv2.waitKey(1) == ord('q'):
        break

# Завершаем видеопоток
videocapture.release()

# Закрываем все окна интерфейса
cv2.destroyAllWindows()